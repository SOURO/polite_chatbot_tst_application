{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d39f7e-58d3-427f-87b5-64588ffb17e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d79508c-e8c3-4e15-8a29-30a267d63924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f9d165-df21-48b0-a2f8-883d3c2b69e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ca0c8d-f517-4845-ae0f-909786759155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52752028-baa8-4adb-90cf-c3389da66dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_utterances_polite = list()\n",
    "with open('../responses/train_polite_res_direct.pkl', 'rb') as f:\n",
    "    train_utterances_polite = pickle.load(f)\n",
    "    train_utterances_polite = list(map(str.strip, train_utterances_polite))\n",
    "print(len(train_utterances_polite))\n",
    "\n",
    "dev_utterances_polite = list()\n",
    "with open('../responses/dev_polite_res_direct.pkl', 'rb') as f:\n",
    "    dev_utterances_polite = pickle.load(f)\n",
    "    dev_utterances_polite = list(map(str.strip, dev_utterances_polite))\n",
    "print(len(dev_utterances_polite))\n",
    "\n",
    "test_utterances_polite = list()\n",
    "with open('../responses/test_polite_res_direct.pkl', 'rb') as f:\n",
    "    test_utterances_polite = pickle.load(f)\n",
    "    test_utterances_polite = list(map(str.strip, test_utterances_polite))\n",
    "print(len(test_utterances_polite))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d42962-7a42-4c05-b723-b8241b0b2202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "base_path = '../../../dialog_data/dailydialog/'\n",
    "\n",
    "def read_data(data_path):\n",
    "    contexts = []\n",
    "    utterances = []\n",
    "    #inputs = []\n",
    "    with open(base_path+data_path) as f:\n",
    "        train_data = f.readlines()\n",
    "        for line in train_data:\n",
    "            turns = line.split('__eou__')\n",
    "            del turns[-1] #last item is '\\n'\n",
    "            \n",
    "            chat_history = []\n",
    "            for idx in range(len(turns)-1):\n",
    "                chat_history.append(turns[idx].strip())\n",
    "                \n",
    "                if(len(chat_history)>5):\n",
    "                    chat_history = chat_history[-5:]\n",
    "                \n",
    "                if(len(chat_history)%2!=0):\n",
    "                    who = itertools.cycle(['<|user|> ', '<|bot|> '])\n",
    "                    ip = next(who)\n",
    "                elif(len(chat_history)%2==0):\n",
    "                    who = itertools.cycle(['<|bot|> ', '<|user|> '])\n",
    "                    ip = next(who)\n",
    "                for chat in chat_history:\n",
    "                    ip = ip + chat + '\\n' + next(who)\n",
    "                contexts.append(ip)\n",
    "                utterances.append(turns[idx+1].strip())\n",
    "                #inputs.append(ip + turns[idx+1].strip())\n",
    "                \n",
    "        return contexts, utterances #, inputs\n",
    "train_contexts, train_utterances = read_data('train/dialogues_train.txt')\n",
    "dev_contexts, dev_utterances = read_data('validation/dialogues_validation.txt')\n",
    "test_contexts, test_utterances = read_data('test/dialogues_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed01578a-0e59-4607-afba-e30bed31fbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(base_path + 'test/dialogues_test.txt') as myfile:\n",
    "    head = [next(myfile) for x in range(1)]\n",
    "print(head)\n",
    "\n",
    "length = len(head[0].split('__eou__'))\n",
    "\n",
    "print('\\n')\n",
    "for idx in range(int(length)):\n",
    "    print('Context')\n",
    "    print(10*'-')\n",
    "    print(dev_contexts[idx])\n",
    "    \n",
    "    print('\\nUtterance')\n",
    "    print(10*'-')\n",
    "    print(dev_utterances[idx])\n",
    "    \n",
    "    print('\\nPolite Utterance')\n",
    "    print(10*'-')\n",
    "    print(test_utterances_polite[idx])\n",
    "    \n",
    "    # print('\\nInput')\n",
    "    # print(10*'-')\n",
    "    # print(dev_inputs[idx])\n",
    "    \n",
    "    print(50*'=')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d681e823-bab4-4e8f-b111-f576497fbc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.DataFrame(\n",
    "    {'contexts': train_contexts,\n",
    "     'utterances': train_utterances,\n",
    "     'polite_utterances': train_utterances_polite\n",
    "    })\n",
    "train_df.head()\n",
    "\n",
    "dev_df = pd.DataFrame(\n",
    "    {'contexts': dev_contexts,\n",
    "     'utterances': dev_utterances,\n",
    "     'polite_utterances': dev_utterances_polite\n",
    "    })\n",
    "dev_df.head()\n",
    "\n",
    "test_df = pd.DataFrame(\n",
    "    {'contexts': test_contexts,\n",
    "     'utterances': test_utterances,\n",
    "     'polite_utterances': test_utterances_polite\n",
    "    })\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd307f1-0f9c-40e3-83ca-7643e8ccd9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config, GPT2LMHeadModel\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967b0594-1c87-44e2-98e2-524e2d48fa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium', eos_token='<|endoftext|>', pad_token='<|pad|>')\n",
    "tokenizer.add_special_tokens({\"additional_special_tokens\": ['<|bot|>', '<|user|>']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d34ec2-5e99-4484-ad5f-f0d07e758ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The end of sequence token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.eos_token_id), tokenizer.eos_token_id))\n",
    "print(\"The padding token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.pad_token_id), tokenizer.pad_token_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25177b67-58f2-4bcc-b01d-9bc12ac77854",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44370522-be00-4459-98bd-033d0298b93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, contexts, utterances, tokenizer, max_length=256):\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.input_ids = []\n",
    "        self.attn_masks = []\n",
    "        self.cntxt_ids = []\n",
    "\n",
    "        for context, utterance in zip(contexts, utterances):\n",
    "\n",
    "            input_encoding_dict = tokenizer(context + utterance + '<|endoftext|>', truncation=True, max_length=max_length, padding=\"max_length\")\n",
    "            self.input_ids.append(torch.tensor(input_encoding_dict['input_ids']))\n",
    "            self.attn_masks.append(torch.tensor(input_encoding_dict['attention_mask']))\n",
    "\n",
    "            context_encoding_dict = tokenizer(context + '<|endoftext|>', truncation=True, max_length=max_length, padding=\"max_length\") \n",
    "            self.cntxt_ids.append(torch.tensor(context_encoding_dict['input_ids']))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.attn_masks[idx], self.cntxt_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0387f760-bc8a-4a8f-bc30-dd7ea869e7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GPT2Dataset(train_df['contexts'].values.tolist(), train_df['utterances'].values.tolist(), tokenizer, max_length=256)\n",
    "dev_dataset = GPT2Dataset(dev_df['contexts'].values.tolist(), dev_df['utterances'].values.tolist(), tokenizer, max_length=256)\n",
    "\n",
    "# To train with polite utterances, (Change #1)\n",
    "# train_dataset = GPT2Dataset(train_df['contexts'].values.tolist(), train_df['polite_utterances'].values.tolist(), tokenizer, max_length=256)\n",
    "# dev_dataset = GPT2Dataset(dev_df['contexts'].values.tolist(), dev_df['polite_utterances'].values.tolist(), tokenizer, max_length=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fa403a-70eb-45d9-8bf6-8c646693bfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "dev_dataloader = DataLoader(\n",
    "            dev_dataset,\n",
    "            sampler = SequentialSampler(dev_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1faf335-8847-4382-a4c0-5e8161dd2670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration = GPT2Config.from_pretrained('gpt2', output_hidden_states=False)\n",
    "\n",
    "# model = GPT2LMHeadModel.from_pretrained(\"gpt2\", config=configuration)\n",
    "model = GPT2LMHeadModel.from_pretrained(\"GPT2_best_model_polite\")\n",
    "\n",
    "# this step is necessary because I've added some tokens (bos_token, etc) to the embeddings\n",
    "# otherwise the tokenizer and model tensors won't match up\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model.cuda()\n",
    "\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92c70a3-319e-462a-b83d-daa2accd45ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 8\n",
    "learning_rate = 5e-4\n",
    "warmup_steps = 1e2\n",
    "epsilon = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a629aed3-30eb-4d30-8363-2d0ce6f7f5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = learning_rate,\n",
    "                  eps = epsilon\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad98c9bc-6d40-4b15-85ff-90f92fb6f7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "# This changes the learning rate as the training loop progresses\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = warmup_steps, \n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba893adc-d86e-4789-8df9-c1547b72b938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    return str(datetime.timedelta(seconds=int(round((elapsed)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1ccb66-7caf-4377-be02-74e87c2240e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_t0 = time.time()\n",
    "\n",
    "training_stats = []\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "early_stop_cnt = 0\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        #b_labels = batch[0].to(device)\n",
    "        b_labels = torch.where(batch[0] != batch[2], batch[0], -100).to(device)\n",
    "        b_masks = batch[1].to(device)\n",
    "\n",
    "        model.zero_grad()        \n",
    "\n",
    "        outputs = model(  b_input_ids,\n",
    "                          labels=b_labels, \n",
    "                          attention_mask = b_masks,\n",
    "                          token_type_ids=None\n",
    "                        )\n",
    "\n",
    "        loss = outputs[0]  \n",
    "\n",
    "        batch_loss = loss.item()\n",
    "        total_train_loss += batch_loss\n",
    "        #print('Batch {:>5,}  of  {:>5,} Loss: {:>5,}'.format(step, len(train_dataloader), batch_loss))\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)       \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in dev_dataloader:\n",
    "        \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        #b_labels = batch[0].to(device)\n",
    "        b_labels = torch.where(batch[0] != batch[2], batch[0], -100).to(device)\n",
    "        b_masks = batch[1].to(device)\n",
    "        \n",
    "        with torch.no_grad():        \n",
    "\n",
    "            outputs  = model(b_input_ids,\n",
    "                             attention_mask = b_masks,\n",
    "                             labels=b_labels)\n",
    "          \n",
    "            loss = outputs[0]  \n",
    "            \n",
    "        batch_loss = loss.item()\n",
    "        total_eval_loss += batch_loss        \n",
    "\n",
    "    avg_val_loss = total_eval_loss / len(dev_dataloader)\n",
    "    \n",
    "    if avg_val_loss < best_val_loss:\n",
    "        early_stop_cnt = 0\n",
    "\n",
    "    elif avg_val_loss >= best_val_loss:\n",
    "        early_stop_cnt += 1\n",
    "\n",
    "    if(avg_val_loss<best_val_loss):\n",
    "        best_val_loss = avg_val_loss\n",
    "        \n",
    "        # Need to change the name when training with polite data, (Change #2)\n",
    "        model.save_pretrained('GPT2_best_model')\n",
    "        tokenizer.save_pretrained('GPT2_best_model')\n",
    "    \n",
    "    validation_time = format_time(time.time() - t0)    \n",
    "\n",
    "    print(\"Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Need to change the name when training with polite data\n",
    "    with open('GPT2_training_stats.pkl', 'wb') as f:\n",
    "        pickle.dump(training_stats, f)\n",
    "    \n",
    "    if early_stop_cnt == 3:\n",
    "        print('Early Stoping...', flush=True)\n",
    "        break\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a675e1-18c8-462c-8921-5e8889fe973e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display floats with two decimal places.\n",
    "# pd.options.display.max_rows = 2\n",
    "\n",
    "# # Create a DataFrame from our training statistics.\n",
    "# df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# # Use the 'epoch' as the row index.\n",
    "# df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# # A hack to force the column headers to wrap.\n",
    "# #df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "# # Display the table.\n",
    "# df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c43f675-57aa-4e46-a138-502cbb00a70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use plot styling from seaborn.\n",
    "# sns.set(style='darkgrid')\n",
    "\n",
    "# # Increase the plot size and font size.\n",
    "# sns.set(font_scale=1.5)\n",
    "# plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# # Plot the learning curve.\n",
    "# plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "# plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "\n",
    "# # Label the plot.\n",
    "# plt.title(\"Training & Validation Loss\")\n",
    "# plt.xlabel(\"Epoch\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# plt.legend()\n",
    "# plt.xticks([1, 2, 3, 4])\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e551d3c2-10da-4f49-bdf8-ccaa11cbfde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "def gen(context):\n",
    "    context_input_ids = tokenizer.encode(context + '<|endoftext|>', truncation=True, max_length=256, padding=\"max_length\", return_tensors='pt')\n",
    "    gen_outputs = model.generate(context_input_ids.cuda(), max_length=300, min_length=25, do_sample=True, top_k=50, top_p=0.95, num_return_sequences=3)\n",
    "    return tokenizer.batch_decode(gen_outputs[:, context_input_ids.shape[-1]:], skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82544454-b40b-41f8-8b9e-34acd5621f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_df['contexts'].values.tolist()[35])\n",
    "op = gen(test_df['contexts'].values.tolist()[35])\n",
    "print(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06829bff-846e-4968-aaaa-82fd867abda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb72d722-f193-4f7d-b923-27fac6333d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlg_responses_pred_wo = []\n",
    "contexts = test_df['contexts'].values.tolist()\n",
    "for idx in range(1000):\n",
    "#for context in test_df['contexts'].values.tolist():\n",
    "    context = contexts[idx]\n",
    "    dlg_responses_pred_wo.append(gen(context))\n",
    "\n",
    "print(len(dlg_responses_pred_wo))\n",
    "\n",
    "# Need to change the name when training with polite data, (Change #3)\n",
    "with open('GPT2_finetune_polite_best.pkl', 'wb') as f:\n",
    "    pickle.dump(dlg_responses_pred_wo, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6758f4a5-7ba8-4f6d-8056-4e44fe6d77c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e520d934-5a5b-4def-9ce0-d9e9bdb163eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
