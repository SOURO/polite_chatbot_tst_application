{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221bb6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from transformers import BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6b2c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('politeness.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedec764",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932684cc-a065-4ee1-8816-460ce5d5a924",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['txt'].tolist()[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f6e3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['style'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e30ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_labels = df['style'].unique()\n",
    "\n",
    "label_dict = {}\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    label_dict[possible_label] = index\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46971e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['style'].replace(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396f983b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9745448",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['style', 'label', 'split']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8f3045",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d44300",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    df[df['split']=='train'].txt.values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True,\n",
    "    max_length=128,\n",
    "    truncation=True, \n",
    "    padding='max_length',\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    df[df['split']=='val'].txt.values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    max_length=128,\n",
    "    truncation=True, \n",
    "    padding='max_length',\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_data_test = tokenizer.batch_encode_plus(\n",
    "    df[df['split']=='test'].txt.values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True,\n",
    "    max_length=128,\n",
    "    truncation=True, \n",
    "    padding='max_length', \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(df[df['split']=='train'].label.values)\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(df[df['split']=='val'].label.values)\n",
    "\n",
    "input_ids_test = encoded_data_test['input_ids']\n",
    "attention_masks_test = encoded_data_test['attention_mask']\n",
    "labels_test = torch.tensor(df[df['split']=='test'].label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0077aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
    "dataset_test = TensorDataset(input_ids_test, attention_masks_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2d646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset_train), len(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be54c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=len(label_dict),\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5872f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, \n",
    "                              sampler=RandomSampler(dataset_train), \n",
    "                              batch_size=batch_size)\n",
    "\n",
    "dataloader_validation = DataLoader(dataset_val, \n",
    "                                   sampler=SequentialSampler(dataset_val), \n",
    "                                   batch_size=batch_size)\n",
    "\n",
    "dataloader_test = DataLoader(dataset_test, \n",
    "                                   sampler=SequentialSampler(dataset_val), \n",
    "                                   batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f0d6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=1e-5, \n",
    "                  eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c54036",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 8\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=len(dataloader_train)*epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139f31b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
    "\n",
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    \n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ea4c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "seed_val = 17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923079df",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17123e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9385f7-9037-4830-9322-89ed388567c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a23776-64ef-4511-a641-36be2e0f44f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# best_val_loss = float('inf')\n",
    "# early_stop_cnt = 0\n",
    "\n",
    "# for epoch in tqdm(range(1, epochs+1)):\n",
    "    \n",
    "#     model.train()\n",
    "\n",
    "#     start_time = time.time()\n",
    "    \n",
    "#     loss_train_total = 0\n",
    "\n",
    "#     progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "#     for batch in progress_bar:\n",
    "\n",
    "#         model.zero_grad()\n",
    "        \n",
    "#         batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "#         inputs = {'input_ids':      batch[0],\n",
    "#                   'attention_mask': batch[1],\n",
    "#                   'labels':         batch[2],\n",
    "#                  }       \n",
    "\n",
    "#         outputs = model(**inputs)\n",
    "        \n",
    "#         loss = outputs[0]\n",
    "#         loss_train_total += loss.item()\n",
    "#         loss.backward()\n",
    "\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "#         optimizer.step()\n",
    "#         scheduler.step()\n",
    "        \n",
    "#         #progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "         \n",
    "        \n",
    "#     #tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "#     loss_train_avg = loss_train_total/len(dataloader_train)            \n",
    "#     #tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "#     val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "\n",
    "#     if val_loss < best_val_loss:\n",
    "#         early_stop_cnt = 0\n",
    "\n",
    "#     elif val_loss >= best_val_loss:\n",
    "#         early_stop_cnt += 1\n",
    "\n",
    "#     if(val_loss<best_val_loss):\n",
    "#         best_val_loss = val_loss\n",
    "#         torch.save(model.state_dict(), f'finetuned_BERT_best.model')\n",
    "    \n",
    "#     val_f1 = f1_score_func(predictions, true_vals)\n",
    "#     #tqdm.write(f'Validation loss: {val_loss}')\n",
    "#     #tqdm.write(f'F1 Score (Weighted): {val_f1}')\n",
    "\n",
    "#     end_time = time.time()\n",
    "#     epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "#     print(f'Epoch: {epoch + 1:02} | Time: {epoch_mins}m {epoch_secs}s', flush=True)\n",
    "#     print(f'\\tTrain Loss: {loss_train_avg:.3f}', flush=True)\n",
    "#     print(f'\\t Val. Loss: {val_loss:.3f}', flush=True)\n",
    "\n",
    "#     if early_stop_cnt == 3:\n",
    "#         print('Early Stoping...', flush=True)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed89a54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"torch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))\n",
    "# print(\"torch.cuda.memory_reserved: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
    "# print(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(0)/1024/1024/1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0770ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1424e57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=len(label_dict),\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f356d642",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('finetuned_BERT_best.model', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff4ecc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predictions, true_vals = evaluate(dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591bdd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_per_class(predictions, true_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa86463b-566b-440f-b51c-b55f69111a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbls = [0,1,2,3,4,5,6,7,8,9]\n",
    "# classes = ['P_0','P_1','P_2', 'P_3', 'P_4', 'P_5', 'P_6','P_7','P_8','P_9']\n",
    "classes = ['P_2','P_7','P_0', 'P_9', 'P_5', 'P_1', 'P_8','P_6','P_4','P_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f06728-bb1f-400c-ac01-fb18403729b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "preds_flat = np.argmax(predictions, axis=1).flatten()\n",
    "labels_flat = true_vals.flatten()\n",
    "\n",
    "confusion = confusion_matrix(labels_flat, preds_flat, labels=lbls)\n",
    "print('Confusion Matrix')\n",
    "#print(confusion)\n",
    "\n",
    "#confusion_classes_tuples = list(zip(classes, confusion))\n",
    "confusion_df = pd.DataFrame(confusion,\n",
    "                     index = classes,\n",
    "                     columns = classes)\n",
    "print(confusion_df)\n",
    "#confusion_df.to_csv('confusion_matrix', sep='\\t', encoding='utf-8')\n",
    "\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(labels_flat, preds_flat, target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02edd99c-94ba-4809-8894-e32985a1fb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels_dict = dict(zip(lbls,classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b912d24b-50cf-440c-be74-4b53b21c5b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_label(inp):\n",
    "    inputs = tokenizer(inp, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "    # print(predicted_class_id)\n",
    "    # print(class_labels_dict[predicted_class_id])\n",
    "    # print(int(class_labels_dict[predicted_class_id].split('_')[1]))\n",
    "    return int(class_labels_dict[predicted_class_id].split('_')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c64dbc-2bc4-4c11-b33d-0d71335072be",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label(\"good bye. Thank you.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033f467e-c1d3-4539-87fb-655e23e7fb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbeba8a-588a-43d3-ade0-7de70c2d738f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_polite_score(list_pkl):\n",
    "    pred_direct_lists = None\n",
    "    with open(list_pkl, 'rb') as f:\n",
    "        pred_direct_lists = pickle.load(f)\n",
    "\n",
    "    pred_labels = []\n",
    "    for pred_direct in pred_direct_lists[:1000]:\n",
    "        pred_labels.append(pred_label(pred_direct))\n",
    "    print(sum(pred_labels)/len(pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd67d99-84f1-4df1-8c2d-b93430ba54cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_polite_score('../politeness_transfer/direct/src_direct_lists.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76918ade-3777-4d50-8cad-89393e20ecc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_polite_score('../politeness_transfer/direct/trg_direct_lists.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d791e20-24ac-40db-aeb2-f81e0f3a5599",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_polite_score('../politeness_transfer/direct/pred_direct_lists.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d53e2f3-6aa7-4f23-9e59-c2d57aa02998",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_polite_score('../politeness_transfer/gen/pred_gen_lists.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6249905-0266-4138-8097-0a44c8da25fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_0_test = df[(df['split']=='test') & (df['style']=='P_0')].txt.values\n",
    "print(len(P_0_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f64b5c-8c04-4a26-a9b0-6efaab4ad2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_polite_score('P_0_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc0edc0-b8c7-4a33-bc81-8ab5352898fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_polite_score('../politeness_transfer/direct/P_0_test_polite_direct.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fd947c-e435-4cf2-904c-d15958be4db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_polite_score('../politeness_transfer/gen/P_0_test_polite_gen.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9217e299-7d5d-41ae-8c1e-aed454dcb178",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_polite_score('../dialog/daily_dialog/responses/test_res.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1771436-86e8-4677-99f0-7d5b185bafd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_polite_score('../dialog/daily_dialog/without-finetune/dlg_responses_wo_pred_lists.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b32606-75fb-4aaf-8426-2e2c6c49a010",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_polite_score('../dialog/daily_dialog/responses/test_polite_res_direct.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cda003e-f948-4fba-b3ac-3aedccdb9061",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_polite_score('../dialog/daily_dialog/responses/test_polite_res_gen.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd62b06-6657-4cdb-a22c-3b933ca8c349",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_polite_score('../dialog/daily_dialog/finetune/dlg_responses_direct_pred_lists.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7169c60-df9c-43ec-a8b0-fda793481de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_polite_score('../dialog/daily_dialog/finetune-polite/polite_dlg_responses_direct_pred_lists.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5888bf4-275e-48f3-9b06-7cd280b83ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_polite_score('../dialog/daily_dialog/without-finetune/dlg_responses_wo_pred_lists_dialoGPT.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b88221-d9ef-4c6d-8c89-b81de29cd2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_polite_score('../dialog/daily_dialog/finetune/dlg_responses_direct_pred_lists_GPT2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307ffafd-4c2c-440f-b688-cf8f2a436b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_polite_score('../dialog/daily_dialog/without-finetune/dlg_responses_wo_pred_lists_GPT2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98a7b68-7fb9-4b74-91d9-35bfd22a2d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_polite_score('../dialog/daily_dialog/finetune/dlg_responses_direct_pred_lists_DialoGPT.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378bad7e-0750-4211-b606-d4660f34ec9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_polite_score('../dialog/daily_dialog/finetune/DialoGPT_finetune_lastmodel.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618feca7-e274-4d43-8a56-dfa89ac8bb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_polite_score('../dialog/daily_dialog/finetune/DialoGPT_finetune_lastmodel_polite.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2e6d41-aff0-4285-a058-cbfb3bee95d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_polite_score('../dialog/daily_dialog/finetune/GPT2_finetune_last.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c306018f-5bf0-4542-85b3-980aada5af9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_polite_score('../dialog/daily_dialog/finetune/GPT2_finetune_best.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae10088-24d6-4463-83a1-a822a3bae50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_polite_score('../dialog/daily_dialog/finetune/GPT2_finetune_polite_best.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605ac22a-27ae-43f5-bf4b-ea0d8290309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_polite_score('../dialog/daily_dialog/finetune/GPT2_finetune_last_polite.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217dd011-024b-4c74-845d-646e0191352d",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_polite_score('../dialog/daily_dialog/finetune/DialoGPT_finetune_best.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c40fe06-6412-439f-8c8f-a6751112522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_polite_score('../dialog/daily_dialog/finetune/DialoGPT_finetune_polite_best.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bc0175-7b9b-44a4-b751-d96154d7e607",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_polite_score('../dialog/daily_dialog/finetune/GPT2_finetune_tag-gen_polite.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a29f78-7ab0-485c-9591-956f22bad1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_polite_score('../dialog/daily_dialog/finetune-polite/Blenderbot_polite_pred_tag-gen.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd0d279-5979-46dc-84c5-10289b8f477a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(r\"../../../tagger-generator/tag-and-generate-train/experiments/syn_output\", 'r') as fp:\n",
    "#     lines = fp.readlines()\n",
    "#     with open('../politeness_transfer/synthetic_test_polite_tagandgen.pkl', 'wb') as f:\n",
    "#         pickle.dump(lines,f)\n",
    "# with open(r\"../../../tagger-generator/tag-and-generate-train/experiments/train_output\", 'r') as fp:\n",
    "#     lines = fp.readlines()\n",
    "#     print(len(lines))\n",
    "#     with open('../dialog/daily_dialog/responses/tag-gen/train_polite_res.pkl', 'wb') as f:\n",
    "#         pickle.dump(lines,f)\n",
    "# with open(r\"../../../tagger-generator/tag-and-generate-train/experiments/dev_output\", 'r') as fp:\n",
    "#     lines = fp.readlines()\n",
    "#     print(len(lines))\n",
    "#     with open('../dialog/daily_dialog/responses/tag-gen/dev_polite_res.pkl', 'wb') as f:\n",
    "#         pickle.dump(lines,f)\n",
    "# with open(r\"../../../tagger-generator/tag-and-generate-train/experiments/test_output\", 'r') as fp:\n",
    "#     lines = fp.readlines()\n",
    "#     print(len(lines))\n",
    "#     with open('../dialog/daily_dialog/responses/tag-gen/test_polite_res.pkl', 'wb') as f:\n",
    "#         pickle.dump(lines,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1183b6a1-0237-4872-b2a7-6a83e8bb9380",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_polite_score('../politeness_transfer/synthetic_test_polite_tagandgen.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbe4b48-e046-453a-91b6-a7581b289f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_polite_score('../dialog/daily_dialog/responses/tag-gen/test_polite_res.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8a7e82-24f0-4ebc-8d67-783f0b74395e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
