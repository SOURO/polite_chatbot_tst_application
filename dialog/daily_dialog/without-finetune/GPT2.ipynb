{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec35a44-c658-4c7c-bf37-e949eaca58a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f9d165-df21-48b0-a2f8-883d3c2b69e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d42962-7a42-4c05-b723-b8241b0b2202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "base_path = '../../../dialog_data/dailydialog/'\n",
    "\n",
    "def read_data(data_path):\n",
    "    contexts = []\n",
    "    utterances = []\n",
    "    inputs = []\n",
    "    with open(base_path+data_path) as f:\n",
    "        train_data = f.readlines()\n",
    "        for line in train_data:\n",
    "            turns = line.split('__eou__')\n",
    "            del turns[-1] #last item is '\\n'\n",
    "            \n",
    "            chat_history = []\n",
    "            for idx in range(len(turns)-1):\n",
    "                chat_history.append(turns[idx].strip())\n",
    "                \n",
    "                if(len(chat_history)>5):\n",
    "                    chat_history = chat_history[-5:]\n",
    "                \n",
    "                if(len(chat_history)%2!=0):\n",
    "                    who = itertools.cycle(['<|user|> ', '<|bot|> '])\n",
    "                    ip = next(who)\n",
    "                elif(len(chat_history)%2==0):\n",
    "                    who = itertools.cycle(['<|bot|> ', '<|user|> '])\n",
    "                    ip = next(who)\n",
    "                for chat in chat_history:\n",
    "                    ip = ip + chat + '\\n' + next(who)\n",
    "                contexts.append(ip)\n",
    "                utterances.append(turns[idx+1].strip())\n",
    "                inputs.append(ip + turns[idx+1].strip())\n",
    "                \n",
    "        return contexts, utterances, inputs\n",
    "train_contexts, train_utterances, train_inputs = read_data('train/dialogues_train.txt')\n",
    "dev_contexts, dev_utterances, dev_inputs = read_data('validation/dialogues_validation.txt')\n",
    "test_contexts, test_utterances, test_inputs = read_data('test/dialogues_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed01578a-0e59-4607-afba-e30bed31fbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(base_path + 'test/dialogues_test.txt') as myfile:\n",
    "    head = [next(myfile) for x in range(1)]\n",
    "print(head)\n",
    "\n",
    "length = len(head[0].split('__eou__'))\n",
    "\n",
    "print('\\n')\n",
    "for idx in range(int(length)):\n",
    "    print('Context')\n",
    "    print(10*'-')\n",
    "    print(test_contexts[idx])\n",
    "    \n",
    "    print('\\nUtterance')\n",
    "    print(10*'-')\n",
    "    print(test_utterances[idx])\n",
    "    \n",
    "    print('\\nInput')\n",
    "    print(10*'-')\n",
    "    print(test_inputs[idx])\n",
    "    print(50*'=')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d681e823-bab4-4e8f-b111-f576497fbc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_contexts, train_utterances, train_inputs\n",
    "train_df = pd.DataFrame(\n",
    "    {'contexts': train_contexts,\n",
    "     'utterances': train_utterances,\n",
    "     'inputs': train_inputs\n",
    "    })\n",
    "train_df.head()\n",
    "\n",
    "dev_df = pd.DataFrame(\n",
    "    {'contexts': dev_contexts,\n",
    "     'utterances': dev_utterances,\n",
    "     'inputs': dev_inputs\n",
    "    })\n",
    "dev_df.head()\n",
    "\n",
    "test_df = pd.DataFrame(\n",
    "    {'contexts': test_contexts,\n",
    "     'utterances': test_utterances,\n",
    "     'inputs': test_inputs\n",
    "    })\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd307f1-0f9c-40e3-83ca-7643e8ccd9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config, GPT2LMHeadModel\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967b0594-1c87-44e2-98e2-524e2d48fa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', eos_token='<|endoftext|>', pad_token='<|pad|>') #gpt2-medium\n",
    "tokenizer.add_special_tokens({\"additional_special_tokens\": ['<|bot|>', '<|user|>']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d34ec2-5e99-4484-ad5f-f0d07e758ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The max model length is {} for this model, although the actual embedding size for GPT small is 768\".format(tokenizer.model_max_length))\n",
    "print(\"The beginning of sequence token {} token has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.bos_token_id), tokenizer.bos_token_id))\n",
    "print(\"The end of sequence token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.eos_token_id), tokenizer.eos_token_id))\n",
    "print(\"The padding token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.pad_token_id), tokenizer.pad_token_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25177b67-58f2-4bcc-b01d-9bc12ac77854",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1faf335-8847-4382-a4c0-5e8161dd2670",
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = GPT2Config.from_pretrained('gpt2', output_hidden_states=False)\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", config=configuration)\n",
    "\n",
    "# this step is necessary because I've added some tokens (bos_token, etc) to the embeddings\n",
    "# otherwise the tokenizer and model tensors won't match up\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model.cuda()\n",
    "\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e551d3c2-10da-4f49-bdf8-ccaa11cbfde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(src):\n",
    "    input_ids = tokenizer.encode(src, return_tensors='pt').to(device)\n",
    "    #print(input_ids.shape)\n",
    "    gen_outputs = model.generate(input_ids=input_ids, max_length=300, min_length=25, do_sample=True, top_k=50, top_p=0.95, num_return_sequences=3)\n",
    "    return tokenizer.batch_decode(gen_outputs[:, input_ids.shape[-1]:], skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06829bff-846e-4968-aaaa-82fd867abda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb72d722-f193-4f7d-b923-27fac6333d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlg_responses_pred_wo = []\n",
    "for ip in test_df['contexts'].values.tolist():\n",
    "    dlg_responses_pred_wo.append(gen(ip))\n",
    "\n",
    "print(len(dlg_responses_pred_wo))\n",
    "\n",
    "with open('dlg_responses_wo_pred_lists_GPT2.pkl', 'wb') as f:\n",
    "    pickle.dump(dlg_responses_pred_wo, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6758f4a5-7ba8-4f6d-8056-4e44fe6d77c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
