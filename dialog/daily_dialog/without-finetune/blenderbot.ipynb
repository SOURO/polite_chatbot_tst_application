{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848ce54d-115a-4334-a2d1-95770acf49de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipywidgets\n",
    "# !jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fca4405-36ff-4804-8d03-4b19a1874fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from ipywidgets import FloatProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3293881c-975d-4081-b712-318e99c178d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b825788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../../../dialog_data/dailydialog/'\n",
    "\n",
    "def read_data(data_path):\n",
    "    src = []\n",
    "    trg = []\n",
    "    with open(base_path+data_path) as f:\n",
    "        train_data = f.readlines() #f.read().splitlines()\n",
    "        #print(len(train_data))\n",
    "        for line in train_data:\n",
    "            utterences = line.split('__eou__')\n",
    "            del utterences[-1] #last item is '\\n'\n",
    "            src_utterence = []\n",
    "            for idx in range(len(utterences)-1):\n",
    "                # src_utterence=src_utterence+'</s>'+trg_utterence\n",
    "                src_utterence.append(utterences[idx])\n",
    "                \n",
    "                if(len(src_utterence)>5):\n",
    "                   src_utterence = src_utterence[-5:]\n",
    "                \n",
    "                src.append('</s>'.join(src_utterence))\n",
    "                trg_utterence = utterences[idx+1]\n",
    "                #trg_utterence = trg_polite_dict[utterences[idx+1]]\n",
    "                trg.append(trg_utterence)\n",
    "                \n",
    "        return src,trg\n",
    "train_src, train_trg = read_data('train/dialogues_train.txt')\n",
    "print(len(train_src), len(train_trg))\n",
    "dev_src, dev_trg = read_data('validation/dialogues_validation.txt')\n",
    "print(len(dev_src), len(dev_trg))\n",
    "test_src, test_trg = read_data('test/dialogues_test.txt')\n",
    "print(len(test_src), len(test_trg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ea6c77-0dde-4743-9550-877c91be496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def write_res(lines,name):\n",
    "#     with open(name, 'w') as f:\n",
    "#         for line in lines:\n",
    "#             f.write(f\"{line}\\n\")\n",
    "\n",
    "# write_res(train_trg,'train_res')\n",
    "# write_res(dev_trg,'dev_res')\n",
    "# write_res(test_trg,'test_res')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997731cf-07ba-4f28-8c6a-b55340c66faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_src = train_src[0:2]\n",
    "# train_trg = train_trg[0:2]\n",
    "# dev_src = dev_src[0:2]\n",
    "# dev_trg = dev_trg[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa24193f-df30-4362-9e41-0d7082bd467d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(base_path + 'test/dialogues_test.txt') as myfile:\n",
    "    head = [next(myfile) for x in range(1)]\n",
    "print(head)\n",
    "\n",
    "length = len(head[0].split('__eou__'))\n",
    "\n",
    "print('\\n')\n",
    "for idx in range(int(length/2)):\n",
    "    print(test_src[idx])\n",
    "    print(test_trg[idx])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d708e149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.DataFrame(\n",
    "    {'src': train_src,\n",
    "     'trg': train_trg\n",
    "    })\n",
    "train_df.head()\n",
    "\n",
    "dev_df = pd.DataFrame(\n",
    "    {'src': dev_src,\n",
    "     'trg': dev_trg\n",
    "    })\n",
    "dev_df.head()\n",
    "\n",
    "test_df = pd.DataFrame(\n",
    "    {'src': test_src,\n",
    "     'trg': test_trg\n",
    "    })\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6593855e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"90MBB_facebook/blenderbot_small-90M/checkpoint-87000/\"\n",
    "# model_name = \"facebook/blenderbot_small-90M\"\n",
    "# model_name = 'facebook/blenderbot-400M-distill/checkpoint-15615'\n",
    "model_name = 'facebook/blenderbot-400M-distill'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f10e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "# from transformers import BlenderbotSmallTokenizer\n",
    "from transformers import BlenderbotTokenizer\n",
    "import torch\n",
    "\n",
    "tokenizer = BlenderbotTokenizer.from_pretrained(model_name)\n",
    "#tokenizer = BlenderbotSmallTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ae6097",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BlenderbotForConditionalGeneration\n",
    "# from transformers import BlenderbotSmallForConditionalGeneration\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "model = BlenderbotForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "#model = BlenderbotSmallForConditionalGeneration.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4e3bba-7106-4e58-bc11-a726cf3ee753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(src):\n",
    "    src_tknz = tokenizer(src, truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
    "    generated_ids = model.generate(src_tknz[\"input_ids\"].cuda(), max_length=128)\n",
    "\n",
    "    return tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5080dd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(50):\n",
    "    print('src:', test_df['src'].values.tolist()[idx])\n",
    "    print('trg:', test_df['trg'].values.tolist()[idx])\n",
    "\n",
    "    print('pred:', gen(test_df['src'].values.tolist()[idx]))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a515a9-c698-4973-a393-660df6931ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e24411b-7f86-42d3-b79d-02f2c907223f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlg_responses_pred_wo = []\n",
    "for idx in range(len(test_df['src'].values.tolist())):\n",
    "    dlg_responses_pred_wo.append((gen(test_df['src'].values.tolist()[idx])))\n",
    "\n",
    "print(len(dlg_responses_pred_wo))\n",
    "\n",
    "with open('dlg_responses_wo_pred_lists.pkl', 'wb') as f:\n",
    "    pickle.dump(dlg_responses_pred_wo, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
